{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3411ff94",
   "metadata": {},
   "source": [
    "This notebook provides some examples on two-qubit tomography. \n",
    "\n",
    "## Initialization\n",
    "\n",
    "### Imports\n",
    "\n",
    "First, we'll do the meeded imports. Note that library's .py files are directly accessed from the folder `solver`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd1534bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import warnings\n",
    "assert path.exists(\"solver\") \n",
    "assert path.exists(\"solver/utils\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc82be82-30c8-4c8d-bb24-6d5da7a9012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9858bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phone\\RQC\\Artem_git\\monitoring-system\\solver\\noising_tools.py:12: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(ind == 0, \"WIP\")\n",
      "C:\\Users\\phone\\RQC\\Artem_git\\monitoring-system\\solver\\noising_tools.py:24: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(ind == 0, \"WIP\")\n",
      "C:\\Users\\phone\\RQC\\Artem_git\\monitoring-system\\solver\\noising_tools.py:36: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(ind == 0, \"WIP\")\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():  # warning still somehow pierces through, so I cleared the cell output\n",
    "    import tensorflow as tf  # tf 2.x\n",
    "    import tensornetwork as tn\n",
    "    tn.set_default_backend(\"tensorflow\")\n",
    "    \n",
    "import numpy as np\n",
    "import QGOpt as qgo\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import solver.utils.general_utils as util\n",
    "import solver.noising_tools as ns\n",
    "import solver.utils.channel_utils as c_util\n",
    "import solver.file_management as fm\n",
    "import solver.circuits_generation as cg\n",
    "\n",
    "from solver.QCCalc import QCEvaluator\n",
    "from solver.experiments import ExperimentConductor, assert_psi2_eq_1\n",
    "from solver.utils.misc import unwrap_dict, NconTemplate, INT, FLOAT, COMPLEX, ID_GATE\n",
    "from solver.QCSolver import QGOptSolver, get_complex_channel_form, QGOptSolverDebug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5f2763",
   "metadata": {},
   "source": [
    "### Quantum gates preparation\n",
    "\n",
    "Let us conduct a simple experiment which makes quantum tomography of gates $\\sf RX$, $\\sf RY$ and $\\sf CX$. $\\sf RX$ and $\\sf RY$ represent unitary rotations with angle $\\pi/2$, while $\\sf CX$ represents the controlled NOT gate. These quantum gates can be expressed as unitary operators as follows:\n",
    "$$\n",
    "{\\sf RX} =  \\begin{bmatrix}\n",
    "            \\cos(\\pi/4) & -\\imath \\sin(\\pi/4)\\\\\n",
    "            -\\imath \\sin(\\pi/4) & \\cos(\\pi/4)\n",
    "        \\end{bmatrix},  \n",
    "{\\sf RY} =  \\begin{bmatrix}\n",
    "            \\cos(\\pi/4) & -\\sin(\\pi/4)\\\\\n",
    "            \\sin(\\pi/4) & \\cos(\\pi/4)\n",
    "        \\end{bmatrix},\n",
    "{\\sf CX} =      \n",
    "    \\begin{bmatrix}\n",
    "        1&0&0&0\\\\0&1&0&0\\\\0&0&0&1\\\\0&0&1&0\n",
    "    \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "We will also need an identity matrix: both for providiing a fictionary measurement gate (SPAM operation) and for internal purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101dcb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rx: [[0.707+0.j    0.   -0.707j]\n",
      " [0.   -0.707j 0.707+0.j   ]]\n",
      "Ry: [[ 0.707+0.j -0.707+0.j]\n",
      " [ 0.707+0.j  0.707+0.j]]\n"
     ]
    }
   ],
   "source": [
    "Rx = util.create_unitary_rotation_x(math.pi/2)\n",
    "Ry = util.generalized_rotation_y(math.pi/2)\n",
    "print('Rx:', Rx.numpy().round(3))\n",
    "print('Ry:', Ry.numpy().round(3))\n",
    "\n",
    "CX_44 = tf.constant([[1, 0, 0, 0],\n",
    "                     [0, 1, 0, 0],\n",
    "                     [0, 0, 0, 1],\n",
    "                     [0, 0, 1, 0]], dtype=COMPLEX)\n",
    "\n",
    "E = tf.eye(2, dtype=COMPLEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b3fde",
   "metadata": {},
   "source": [
    "Now it is time to convert these unitary operators to quantum channels. Two-qubit gates need to be reshaped first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d196074",
   "metadata": {},
   "outputs": [],
   "source": [
    "CX = util.convert_44_to_2222(CX_44)\n",
    "\n",
    "Rx_channel = c_util.convert_1qmatrix_to_channel(Rx)\n",
    "Ry_channel = c_util.convert_1qmatrix_to_channel(Ry)\n",
    "E_channel = c_util.convert_1qmatrix_to_channel(E)\n",
    "CX_channel = c_util.convert_2qmatrix_to_channel(CX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df4407",
   "metadata": {},
   "source": [
    "Now we need to make set of channels from this. The recommended order is to fill all single-qubit gates, then internal identity gate (**this is important**), then all two-qubit gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40653164",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_pure_channels = {'Rx':Rx_channel,\n",
    "                         'Ry':Ry_channel,\n",
    "                         'M': E_channel,\n",
    "                         ID_GATE:E_channel,\n",
    "                         'CX': CX_channel}                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3044cd",
   "metadata": {},
   "source": [
    "### Circuits preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394ce905",
   "metadata": {},
   "source": [
    "We will need a `DataGenerator`, which can (surprisingly) generate quantum circuits, and convert quantum circuits to the tensor network template form. To initialize it, we need the gates' labels, and it's quite important to pass them in the same order as stated in `default_pure_channels` **without the internal `ID_GATE`**. Some day this inconvenient feature will be fixed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100ce769",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_QUBITS = 2\n",
    "\n",
    "gates_labels = list(default_pure_channels.keys())\n",
    "gates_labels.remove(ID_GATE)\n",
    "\n",
    "gen = cg.DataGenerator(qubits_num=NUM_QUBITS,\n",
    "                       gates_names=gates_labels, # ['Rx', 'Ry', 'M', 'CX']\n",
    "                       single_qub_gates_num=3,\n",
    "                       two_qub_gates_num=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c53092",
   "metadata": {},
   "source": [
    "However, let's resort to using just the second option of what `DataGenerator` can do. We will not use any pre-made generators, but rather create the set of circuits ourselves. For simple tomography experiment, one can use different sets of:\n",
    "* state preparation part\n",
    "* middle part a. k. a. gates to be tomographied\n",
    "* measurement gates part\n",
    "\n",
    "TODO: explain why these sets are usually taken for tomography and how exactly they are conducted.\n",
    "\n",
    "The quantum circuits is now defined as sequence of quantum gates applied to a different qubits. In the code, the so-called \"human\" quantum circuit is represented as a list of strings, with each string having format\n",
    "'LABEL_TARGET' for single-qubit gates or 'LABEL_TARGET1_TARGET2' for two-qubit gates. The order of targets is important, and controlling qubit goes **first**.\n",
    "\n",
    "We can write a simple function which generates a list of all available combinations. First, let's generate all circuits without CX gates in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa6f47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_circs_without_CX():\n",
    "    preps = [[],\n",
    "             ['Rx_0', 'Rx_1'],\n",
    "             ['Ry_0', 'Ry_1'],\n",
    "             ['Rx_0', 'Rx_0', 'Rx_1', 'Rx_1']]\n",
    "    \n",
    "    toms = [[],\n",
    "            ['Rx_0', 'Rx_1'],\n",
    "            ['Ry_0', 'Ry_1']]\n",
    "    \n",
    "    meass = [['M_0', 'M_1'],\n",
    "             ['Rx_0', 'Rx_1', 'M_0', 'M_1'],\n",
    "             ['Ry_0', 'Ry_1', 'M_0', 'M_1']]\n",
    "    \n",
    "    ans = []\n",
    "    \n",
    "    for prep in preps:\n",
    "        for tom in toms:\n",
    "            for meas in meass:\n",
    "                ans.append(prep + tom + meas)\n",
    "                \n",
    "    return ans\n",
    "\n",
    "circs1 = gen_circs_without_CX()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05a5e9e",
   "metadata": {},
   "source": [
    "We can print these circuits represented by sequences of gates. Note that the labels of gates in string format are constistent with labels we gave in `default_pure_channels` dict as keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f1e7b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Rx', 'Ry', 'M', '_E', 'CX'])\n",
      "Circuit #8 is represented as ['Ry_0', 'Ry_1', 'Ry_0', 'Ry_1', 'M_0', 'M_1']\n",
      "Circuit #24 is represented as ['Ry_0', 'Ry_1', 'Ry_0', 'Ry_1', 'M_0', 'M_1']\n",
      "Circuit #3 is represented as ['Rx_0', 'Rx_1', 'M_0', 'M_1']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "print(default_pure_channels.keys())\n",
    "\n",
    "for idx in np.random.choice(np.arange(len(circs1)), 3):\n",
    "    print(f'Circuit #{idx} is represented as {circs1[idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c665a1",
   "metadata": {},
   "source": [
    "Circuits with CX gate between qubits 0 and 1 are made a little bit differently: the set of preparations and measurements is now extended (it allows asymmetric measurements), but now we have only one choice for middle part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df012a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "def gen_circs_with_CX():\n",
    "    preps_0 = [[],\n",
    "               ['Rx_0'],\n",
    "               ['Ry_0'],\n",
    "               ['Rx_0', 'Rx_0']]\n",
    "    preps_1 = [[],\n",
    "               ['Rx_1'],\n",
    "               ['Ry_1'],\n",
    "               ['Rx_1', 'Rx_1']]\n",
    "    \n",
    "    meas_0 = [['M_0'],\n",
    "              ['Rx_0', 'M_0'],\n",
    "              ['Ry_0', 'M_0']]\n",
    "    meas_1 = [['M_1'],\n",
    "              ['Rx_1', 'M_1'],\n",
    "              ['Ry_1', 'M_1']]\n",
    "    \n",
    "    ans = []\n",
    "    tup_ans = []\n",
    "    \n",
    "    for prep_0 in preps_0:\n",
    "        for prep_1 in preps_1:\n",
    "            for m_0 in meas_0:\n",
    "                for m_1 in meas_1:\n",
    "                    ans.append(prep_0 + prep_1 + ['CX_0_1'] + m_0 + m_1)\n",
    "                \n",
    "    return ans\n",
    "\n",
    "circs2 = gen_circs_with_CX()\n",
    "\n",
    "circs = circs1 + circs2\n",
    "print(len(circs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36557a30",
   "metadata": {},
   "source": [
    "So far so good: we have just created 180 different circuits which allow for quantum gate tomography. Now need to convert it into tensor network templates format. Templates are stored in a dict, so they require some keys to access them. Right now we won't use any names, and just convert the index of a circuit to string - but you can name your circuits arbitratily. \n",
    "\n",
    "Also we add an empty circuit for demonstration purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34bb1f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantum circuit with very simple \"human\" representation \n",
      "['Rx_0', 'Rx_0', 'CX_0_1', 'Ry_0', 'M_0', 'Rx_1', 'M_1']\n",
      "has a very scary tensor network template \n",
      "[[0, 0, 7, 2, 4, 1, 5], [[3, 1], [4, 3], [6, 5, 2, 4], [7, 5], [-1, 7], [9, 6], [-2, 9]], [3, 4, 5, 6, 7, 9], [-1, -2]]\n",
      "A quantum circuit with very simple \"human\" representation \n",
      "['Rx_0', 'Ry_1', 'CX_0_1', 'M_0', 'Ry_1', 'M_1']\n",
      "has a very scary tensor network template \n",
      "[[0, 3, 7, 4, 3, 5], [[3, 1], [4, 2], [6, 5, 4, 3], [-1, 5], [8, 6], [-2, 8]], [3, 4, 5, 6, 8], [-1, -2]]\n",
      "A quantum circuit with very simple \"human\" representation \n",
      "['Rx_0', 'Rx_0', 'Ry_1', 'CX_0_1', 'Rx_0', 'M_0', 'Ry_1', 'M_1']\n",
      "has a very scary tensor network template \n",
      "[[0, 0, 3, 7, 0, 4, 3, 5], [[3, 1], [4, 3], [5, 2], [7, 6, 5, 4], [8, 6], [-1, 8], [10, 7], [-2, 10]], [3, 4, 5, 6, 7, 8, 10], [-1, -2]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)\n",
    "\n",
    "ncon_tmpls = gen.get_tmpl_dict_from_human_circs(circs + [[]])  # add an empty circuit\n",
    "\n",
    "for idx in np.random.choice(np.arange(len(circs)), 3):\n",
    "    print(f'A quantum circuit with very simple \"human\" representation \\n{circs[idx]}'\n",
    "    f'\\nhas a very scary tensor network template \\n{ncon_tmpls[str(idx)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aec358",
   "metadata": {},
   "source": [
    "Right now we will not explain how these tensor network templates work. However, this form is widely used in the package `ncon` from `tensornetwork` library, and if you are familiar with it, you can read the tensor network templates just as \"human\" circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e7fd962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An empty quantum circuit was converted to [[6, 6], [[-1, 1], [-2, 2]], [], [-1, -2]]\n"
     ]
    }
   ],
   "source": [
    "print(f'An empty quantum circuit was converted to {list(ncon_tmpls.values())[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30d08f",
   "metadata": {},
   "source": [
    "Sometimes, your circuit will have no gates at certain qubits (or it may have no gates at all). DataGenerator notices that and contracts inputs with outputs using the special `ID_GATE` we passed above, which has the index of 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0acfb74",
   "metadata": {},
   "source": [
    "### Noising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ca6df6",
   "metadata": {},
   "source": [
    "The noise config may look quite complicated, but it's easier to grasp when you look closely at its element.\n",
    "Element of a noise config is a tuple contaning\n",
    "* label of a gate\n",
    "* id of a gate; in a single-qubit case it coincides with qubit number and in two-qubit case it can be obtained by enumerating all qubit pairs. E. g. in three-qubit scenario, targer pairs `[(0, 1), (0, 2), (1, 0), (1, 2), (2, 0), (2, 1)]` will be mapped to ids from 0 to 5.\n",
    "* function to noise - it's best to use a pre-defined function, which has four parameters\n",
    "    * parameter for gaussian blur \n",
    "    * parameter for depolarization channel\n",
    "    * parameter for amplitude damping\n",
    "    * parameter for phase damping\n",
    "\n",
    "TODO: tell about noise params more thoroughly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a277c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_cfg = []\n",
    "\n",
    "# comments are fidelities between noised and ideal versions of gate\n",
    "noise_cfg.append(('Rx', 0, ns.make_1q_4pars_channel, 0.065, 0.03, 0.005, 0.005)) # 0.97135\n",
    "noise_cfg.append(('Rx', 1, ns.make_1q_4pars_channel, 0.05, 0.03, 0.03, 0.0)) # 0.96153\n",
    "\n",
    "noise_cfg.append(('Ry', 0, ns.make_1q_4pars_channel, 0.02, 0.02, 0.02, 0.02)) # 0.9701\n",
    "noise_cfg.append(('Ry', 1, ns.make_1q_4pars_channel, 0.06, 0.01, 0.03, 0.03)) # 0.96826\n",
    "\n",
    "noise_cfg.append(('M', 0, ns.make_1q_4pars_channel, 0.0, 0.04, 0.02, 0.02)) # 0.95567\n",
    "noise_cfg.append(('M', 1, ns.make_1q_4pars_channel, 0.0, 0.03, 0.03, 0.03)) # 0.95583\n",
    "\n",
    "noise_cfg.append(('CX', 0, ns.make_2q_4pars_channel, 0.05, 0.02, 0.02, 0.02)) # 0.93728"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f5a54",
   "metadata": {},
   "source": [
    "We can apply this noising function to a gate and see how it changes. For example, we may calculate fidelity between \"pure\" and \"noised\" quantum channels. Notice the small machine calculation error in imaginary part - we know that it should be equal to zero, but nothing is perfect. There are other metrics to compute (e. g. diamond norm). Since diamond norm is calculated via external Qiskit library, its output is quite beautiful without any formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f8bab94-944e-403c-8d50-ac146fd2c06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phone\\AppData\\Local\\Temp\\__autograph_generated_filey72xxm94.py:10: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (ag__.ld(ind) == 0, 'WIP')\n",
      "C:\\Users\\phone\\AppData\\Local\\Temp\\__autograph_generated_filemg1r8hk1.py:10: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (ag__.ld(ind) == 0, 'WIP')\n",
      "C:\\Users\\phone\\AppData\\Local\\Temp\\__autograph_generated_file_q0fzkyt.py:10: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (ag__.ld(ind) == 0, 'WIP')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity is (0.9664442998015647+2.079481816600584e-09j)\n",
      "Diamond norm is 0.0698386991392608\n"
     ]
    }
   ],
   "source": [
    "pure_channel = Rx_channel\n",
    "noised_channel = ns.make_1q_4pars_channel(pure_channel, [0.05, 0.02, 0.02, 0.02])\n",
    "print('Fidelity is', util.fidel_calc_1q(pure_channel, noised_channel).numpy())\n",
    "print('Diamond norm is', util.diamond_norm_1q(pure_channel, noised_channel).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5086f51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity is (0.9372607319998256+1.3424706306631773e-08j)\n",
      "Diamond norm is 0.13689392477603946\n"
     ]
    }
   ],
   "source": [
    "pure_channel = CX_channel\n",
    "noised_channel = ns.make_2q_4pars_channel(pure_channel, [0.05, 0.02, 0.02, 0.02])\n",
    "print('Fidelity is', util.fidel_calc_2q(pure_channel, noised_channel).numpy())\n",
    "print('Diamond norm is', util.diamond_norm_2q(pure_channel, noised_channel).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08abbbb7",
   "metadata": {},
   "source": [
    "## Conducting experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d017576",
   "metadata": {},
   "source": [
    "We have a class called ExperimentConductor contaning all the parameters for our experiment. It has the:\n",
    "* ideal gate set ${\\bf G}^{\\rm ideal}$\n",
    "* noise configuration we have just made\n",
    "* experiment name for working with files (more on that later)\n",
    "* number of qubits\n",
    "* learning rate\n",
    "* regularization coefficients for one-qubit and two-qubit gates\n",
    "* sample size a. k. a. shots number for sample generation (8192 is a realistic number you can get at real quantum PC)\n",
    "\n",
    "Since we're not conducting any complicated experiments, the full functionality of this class will not be unleashed. However, it's convenient to store all the information together in order not to lose track. Notice the learning rate, regularizations and iterations hyperparameteres - they are all set here. These are not optimal but get the job done. Feel free to experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf635d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function make_1q_4pars_channel at 0x00000217DC733E20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function make_1q_4pars_channel at 0x00000217DC733E20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    exp_test = ExperimentConductor(pure_channels_set=default_pure_channels,\n",
    "                                   noise_cfg=noise_cfg,\n",
    "                                   exp_name='tomo_tutorial',\n",
    "                                   qubits_num=NUM_QUBITS,\n",
    "                                   lr=0.002,  \n",
    "                                   lmbd1=100,\n",
    "                                   lmbd2=100,\n",
    "                                   iterations=300,\n",
    "                                   sample_size=8192)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d2a7bf",
   "metadata": {},
   "source": [
    "First, let's use solver as a sample generator in order to generate the outcomes for each circuit. In the current version of the program, the number of outcomes (`sample_size`) is shared across all circuits.   \n",
    "We are using the debug version of QGOptSolver since it gives more info. Pay attention to the variable `noise_iter0` - it determines the initial approximation. If you suspect your data to be noisy, increase it. It is **SUPER** important for convergence to set this above zero in order not to get stuck in a local minima! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c0de7-679b-4765-b29d-a9d31687ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "circs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed4da81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated set is generated from pure channels by applying noise parameters [0.07 0.   0.  ]\n",
      "generating samples... 25% 50% 75% Done!\n"
     ]
    }
   ],
   "source": [
    "QC_t = QGOptSolverDebug(qudits_num=NUM_QUBITS,\n",
    "                        single_qud_gates_names={'Rx', 'Ry', 'M'},\n",
    "                        two_qud_gates_names={'CX'},\n",
    "                        pure_channels_set=default_pure_channels,\n",
    "                        compress_samples=True,\n",
    "                        noise_params=exp_test.noise_params,\n",
    "                        noise_iter0=0.07)\n",
    "\n",
    "for name, tmpl in ncon_tmpls.items():\n",
    "    QC_t.add_circuit(tn_template=tmpl, name=name)\n",
    "    \n",
    "QC_t.generate_all_samples(v=False, smpl_size=exp_test.sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44b27f",
   "metadata": {},
   "source": [
    "Now we need to setup our manifold for quantum channels optimization and grab optimizer itself from `QGOpt` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dbc3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "manif = qgo.manifolds.ChoiMatrix()\n",
    "opt_t = qgo.optimizers.RAdam(manif, exp_test.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc75cc9",
   "metadata": {},
   "source": [
    "We are ready to minimize the loss hard-coded in the solver:   \n",
    "TODO: talk about loss.  \n",
    "See article for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3c58eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 300 iterations passed\n",
      "30 out of 300 iterations passed\n",
      "60 out of 300 iterations passed\n",
      "90 out of 300 iterations passed\n",
      "120 out of 300 iterations passed\n",
      "150 out of 300 iterations passed\n",
      "180 out of 300 iterations passed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10396\\825949545.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m loss_dynamics_t, norms_dict, _ = QC_t.train_optimizer(opt=opt_t,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                                       \u001b[0mlmbd1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexp_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlmbd1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                       \u001b[0mlmbd2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexp_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlmbd2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                       \u001b[0miters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexp_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\RQC\\Artem_git\\monitoring-system\\solver\\QCSolver.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, opt, lmbd1, lmbd2, iters, v, fid_ctr, norm_ctr, timestamp)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;31m# optimization loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlmbd1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbd2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_and_grad_with_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlmbd1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbd2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\RQC\\Artem_git\\monitoring-system\\solver\\QCSolver.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, lmbd1, lmbd2, v)\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;31m# Loss from circuits is calculated; now time to calculate reg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mtotal_logp\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_gaussian_reg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannels_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbd1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbd2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m             \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimated_gates_dict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#производная первого аргумента по второму\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\phone\\RQC\\Artem_git\\monitoring-system\\venv_monitor\\Lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1059\u001b[0m               output_gradients))\n\u001b[0;32m   1060\u001b[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001b[0;32m   1061\u001b[0m                           for x in output_gradients]\n\u001b[0;32m   1062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1064\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\phone\\RQC\\Artem_git\\monitoring-system\\venv_monitor\\Lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     raise ValueError(\n\u001b[0;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\phone\\RQC\\Artem_git\\monitoring-system\\venv_monitor\\Lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gradient_tape/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\phone\\RQC\\Artem_git\\monitoring-system\\venv_monitor\\Lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    828\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Transpose\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_TransposeGrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m   \u001b[1;34m\"\"\"Returns unshuffle(grad).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m   \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 832\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvert_permutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\phone\\RQC\\Artem_git\\monitoring-system\\venv_monitor\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\phone\\RQC\\Artem_git\\monitoring-system\\venv_monitor\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\phone\\RQC\\Artem_git\\monitoring-system\\venv_monitor\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(a, perm, name, conjugate)\u001b[0m\n\u001b[0;32m   2378\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2379\u001b[0m       \u001b[0mtranspose_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mperm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2382\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtranspose_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2384\u001b[0m     \u001b[0mrank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\phone\\RQC\\Artem_git\\monitoring-system\\venv_monitor\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, perm, name)\u001b[0m\n\u001b[0;32m  14937\u001b[0m         _ctx, \"Transpose\", name, x, perm)\n\u001b[0;32m  14938\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  14939\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  14940\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 14941\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  14942\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  14943\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  14944\u001b[0m       return transpose_eager_fallback(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_dynamics_t, norms_dict, _ = QC_t.train_optimizer(opt=opt_t,\n",
    "                                                      lmbd1=exp_test.lmbd1,\n",
    "                                                      lmbd2=exp_test.lmbd2,\n",
    "                                                      iters=exp_test.iters,\n",
    "                                                      v=1,\n",
    "                                                      fid_ctr=1, # we'd like to calculate fidelities every step\n",
    "                                                      norm_ctr=-1)  # we don't calculate L1 norms here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb96d8",
   "metadata": {},
   "source": [
    "We can look at our loss dymamics to see that learning process was OK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f59d41d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_dynamics_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mloss_dynamics_t\u001b[49m)  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss_dynamics_t' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(loss_dynamics_t)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8dec86",
   "metadata": {},
   "source": [
    "Could use even smaller learning rate, but whatever."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5051cc",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f68c14e",
   "metadata": {},
   "source": [
    "The debug version of the solver has the ability to extract norms $\\left( \\| {\\bf G}^{\\rm est}(l,t) - {\\bf G}^{\\rm true}(l,t) \\|, \\; \\| {\\bf G}^{\\rm est}(l,t) - {\\bf G}^{\\rm ideal}(l,t) \\| \\right) $ during each iteration of algorithm. These norms will provide us with beautiful graphs. For most of the gates, diamond norm in extracted, and for measurement gate ${\\sf M}$ it is POVM norm (see article for details).  \n",
    "\n",
    "Let's plot these norms vs. algorithm iteration number to prove that our algorithm did a good job. Remember, since we were the ones who generated the noise, we have information about norms between true vestions and estimated versions of quantum gates $\\| {\\bf G}^{\\rm est}(l,t) - {\\bf G}^{\\rm true}(l,t) \\| $. Of course, in real experiment we would be able to see only norms between ideal and estimated versions.\n",
    "\n",
    "First, we extract the norms between true and ideal quantum gates; these norms will appear as horizontal lines a. k. a. answers. Our goal is to make ideal-estimated norm $\\| {\\bf G}^{\\rm est}(l,t) - {\\bf G}^{\\rm ideal}(l,t) \\| $ as close as possible to true-ideal norm $\\| {\\bf G}^{\\rm true}(l,t) - {\\bf G}^{\\rm ideal}(l,t) \\| $. This process is related to minimizing the true-estimated norm. Note that unlike in the article, here the number of circuis stays the same! X axis represents the number of iterations which is just a hyperparameter in the big experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "HLINES = defaultdict(list)\n",
    "\n",
    "for label in QC_t.hidden_gates_dict:\n",
    "    sublist = QC_t.hidden_gates_dict[label]\n",
    "    for idx, gate in enumerate(sublist):\n",
    "        if label == 'CX':\n",
    "            HLINES[label].append(util.diamond_norm_2q(gate, default_pure_channels[label]))\n",
    "        elif label == 'M':\n",
    "            HLINES[label].append(util.get_povm_dist(gate, default_pure_channels[label]))\n",
    "        else:\n",
    "            HLINES[label].append(util.diamond_norm_1q(gate, default_pure_channels[label]))\n",
    "            \n",
    "COLORS = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:gray']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2b565",
   "metadata": {},
   "source": [
    "### Plotting norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diamond_norms(ax1, ax2):\n",
    "    colors_idx = [0, 0]\n",
    "    \n",
    "    for key in norms_dict.keys():\n",
    "        label, idx, norm_type = key\n",
    "\n",
    "        if label in ['Rx', 'Ry', 'CX']:\n",
    "            if label == 'CX' and idx == 1:\n",
    "                continue\n",
    "                \n",
    "            if norm_type == 'i':\n",
    "                ax1.plot(np.abs(norms_dict[label, idx, norm_type]),\n",
    "                         label=f'{label}{idx}',\n",
    "                         color=COLORS[colors_idx[0]])\n",
    "                ax1.axhline(y=HLINES[label][idx],\n",
    "                            color=COLORS[colors_idx[0]],\n",
    "                            linestyle=':')\n",
    "                colors_idx[0] += 1\n",
    "\n",
    "            else:\n",
    "                ax2.plot(np.abs(norms_dict[label, idx, norm_type]),\n",
    "                         label=f'{label}{idx}',\n",
    "                         color=COLORS[colors_idx[1]])\n",
    "                colors_idx[1] += 1\n",
    "            \n",
    "    ax1.set_title('Diamond norm(ideal, est)', {\"size\":18})\n",
    "    ax1.set_xlabel('Algorithm iteration number', {\"size\":16})\n",
    "\n",
    "    ax2.set_title('Diamond norm(true, est)', {\"size\":18})\n",
    "    ax2.set_xlabel('Algorithm iteration number', {\"size\":16})\n",
    "\n",
    "    ax1.legend(prop={'size': 14})\n",
    "    ax2.legend(prop={'size': 14})\n",
    "        \n",
    "        # ax.set_ylim(0.92, 0.98)\n",
    "        \n",
    "def plot_povm_norms(ax1, ax2):\n",
    "    colors_idx = [0, 0]\n",
    "    \n",
    "    for key in norms_dict.keys():\n",
    "        label, idx, norm_type = key\n",
    "\n",
    "        if label == 'M':\n",
    "            if norm_type == 'i':\n",
    "                ax1.plot(np.abs(norms_dict[label, idx, norm_type]),\n",
    "                         label=f'{label}{idx}',\n",
    "                         color=COLORS[colors_idx[0]])\n",
    "                ax1.axhline(y=HLINES[label][idx],\n",
    "                            color=COLORS[colors_idx[0]],\n",
    "                            linestyle=':')\n",
    "                colors_idx[0] += 1\n",
    "\n",
    "            else:\n",
    "                ax2.plot(np.abs(norms_dict[label, idx, norm_type]),\n",
    "                         label=f'{label}{idx}',\n",
    "                         color=COLORS[colors_idx[1]])\n",
    "                colors_idx[1] += 1\n",
    "            \n",
    "    ax1.set_title('POVM norm(ideal, est)', {\"size\":18})\n",
    "    ax1.set_xlabel('Algorithm iteration number', {\"size\":16})\n",
    "\n",
    "    ax2.set_title('POVM norm(true, est)', {\"size\":18})\n",
    "    ax2.set_xlabel('Algorithm iteration number', {\"size\":16})\n",
    "\n",
    "    ax1.legend(prop={'size': 14})\n",
    "    ax2.legend(prop={'size': 14})\n",
    "        \n",
    "        # ax.set_ylim(0.92, 0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c5b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(2, 2, figsize=(16, 12))\n",
    "ax1, ax2, ax3, ax4 = [a for sublist in axarr for a in sublist]\n",
    "plot_diamond_norms(ax1, ax2)\n",
    "plot_povm_norms(ax3, ax4)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c6b71b",
   "metadata": {},
   "source": [
    "As you can see, our alrogithm achieved decent results while using not much information (180 circuits with 8192 samples). Notice how the too big initial noise `noise_iter0=0.07` forces algorithm to think that gates are in fact less noisy then it thought, which is reflected in the graphs: gates norms are decreasing with iterations. Try setting `noise_iter0=0.05` and re-running the notebook to achieve somewhat better final results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cd1840",
   "metadata": {},
   "source": [
    "### Post-procesing, saving and loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f1dba",
   "metadata": {},
   "source": [
    "You may have a need to conduct experiments on different devices. Or just conveniently save the results somewhere in order to access them later. Fortunately, there's a file `solver/file_management.py` dedicated to such tasks. The code there should be simple and easy to read.\n",
    "\n",
    "The most important information after an algorithm has done its job now resides in the member `estimated_gates_dict` of a `Solver` class. However, we need to convert it to complex channel form for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea31ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result = get_complex_channel_form(QC_t.estimated_gates_dict)\n",
    "# print(dict_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b3977",
   "metadata": {},
   "source": [
    "These are numerical estimations on gates of a quantum processor. Single-qubit gates or SPAM operations have $n$ versions - one for each qubit. Two-qubit gates have $n (n-1)$ versions - one for each pair of qubits. We can save a dict containing this information into a .pickle file, and then extract these tensors somewhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57d60dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.save_tensors_to_file(dict_result, ['tomo-tutorial'], prefix_args=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a85df6",
   "metadata": {},
   "source": [
    "The folder `data\\tomo-tutorial` should now appear, with a .pickle file containing the results of the experiment. Of course, you can instantly load them back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5d2cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuploaded_dict = fm.import_tensors_from_file(['tomo-tutorial'], prefix_args=1)\n",
    "assert reuploaded_dict.keys() == dict_result.keys()\n",
    "for key in reuploaded_dict:\n",
    "    assert tf.abs(tf.linalg.norm(reuploaded_dict[key] - dict_result[key])) < 1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c531f",
   "metadata": {},
   "source": [
    "Sometimes it is desirable to work with Choi matrices which are familiar to many people instead of some quantum channels denoted in some article. There are ways to convert the gate set into Choi matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a49f4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "choi1 = util.choi_swap_1qchannel(dict_result['Rx'][0])\n",
    "choi2 = util.choi_swap_2qchannel(dict_result['CX'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d155376",
   "metadata": {},
   "source": [
    "It may be useful to save not only the final results as tensors, but also the quantum circuits or generated bit strings. This becomes of critical importance when working with external sources of bit strings (e. g. running only the optimizer with pre-generated data). Below are some examples for working with such information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdbe4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.save_bitstrings_to_file(QC_t.samples_compressed, ['tomo-tutorial', 'comp'], prefix_args=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bfb5ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.save_ncon_list_to_file(list(QC_t.tn_templates.values()), ['tomo-tutorial'], prefix_args=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dad9aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.save_ncon_list_to_file(circs + [[]], ['tomo-tutorial', 'human-form'], prefix_args=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2738d0c",
   "metadata": {},
   "source": [
    "Congratulations, we hope you gained a bit of insight about this humble project and maybe even learned something useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a472c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
